{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d85aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data1 = pd.read_csv(r'D:/cv_final_project/z/Bull.csv',header=None,dtype='uint8')\n",
    "data1=data1.astype(np.uint8) \n",
    "\n",
    "data2 = pd.read_csv(r'D:/cv_final_project/z/Cattle.csv',header=None,dtype='uint8')\n",
    "data2=data2.astype(np.uint8) \n",
    "\n",
    "data3 = pd.read_csv(r'D:/cv_final_project/z/Elephant.csv',header=None,dtype='uint8')\n",
    "data3=data3.astype(np.uint8) \n",
    "\n",
    "data4 = pd.read_csv(r'D:/cv_final_project/z/Horse.csv',header=None,dtype='uint8')\n",
    "data4=data4.astype(np.uint8) \n",
    "\n",
    "data5 = pd.read_csv(r'D:/cv_final_project/z/Leopard.csv',header=None,dtype='uint8')\n",
    "data5=data5.astype(np.uint8) \n",
    "\n",
    "data6 = pd.read_csv(r'D:/cv_final_project/z/Monkey.csv',header=None,dtype='uint8')\n",
    "data6=data6.astype(np.uint8) \n",
    "\n",
    "data7 = pd.read_csv(r'D:/cv_final_project/z/Pig.csv',header=None,dtype='uint8')\n",
    "data7=data7.astype(np.uint8)\n",
    "\n",
    "data8 = pd.read_csv(r'D:/cv_final_project/z/Rabbit.csv',header=None,dtype='uint8')\n",
    "data8=data8.astype(np.uint8) \n",
    "\n",
    "data9 = pd.read_csv(r'D:/cv_final_project/z/Sheep.csv',header=None,dtype='uint8')\n",
    "data9=data9.astype(np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1789bbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=17, n_init=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=17, n_init=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=17, n_init=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For data1\n",
    "kmeans_data1 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data1.fit(data1)\n",
    "\n",
    "#For data2\n",
    "kmeans_data2 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data2.fit(data2)\n",
    "\n",
    "#For data3\n",
    "kmeans_data3 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data3.fit(data3)\n",
    "\n",
    "#For data4\n",
    "kmeans_data4 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data4.fit(data4)\n",
    "\n",
    "#For data5\n",
    "kmeans_data5 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data5.fit(data5)\n",
    "\n",
    "#For data6\n",
    "kmeans_data6 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data6.fit(data6)\n",
    "\n",
    "#For data7\n",
    "kmeans_data7 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data7.fit(data7)\n",
    "\n",
    "#For data8\n",
    "kmeans_data8 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data8.fit(data8)\n",
    "\n",
    "#For data8\n",
    "kmeans_data9 = KMeans(n_clusters=17, n_init=10)\n",
    "kmeans_data9.fit(data9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc19b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Save the model to disk for data 1\n",
    "filename_data1 = 'Kmeans_CL_5_Model_data1.sav'\n",
    "with open(filename_data1, 'wb') as file:\n",
    "    pickle.dump(kmeans_data1, file)\n",
    "    \n",
    "# Save the model to disk for data2\n",
    "filename_data2 = 'Kmeans_CL_5_Model_data2.sav'\n",
    "with open(filename_data2, 'wb') as file:\n",
    "    pickle.dump(kmeans_data2, file)\n",
    "    \n",
    "# Save the model to disk for data2\n",
    "filename_data3 = 'Kmeans_CL_5_Model_data3.sav'\n",
    "with open(filename_data3, 'wb') as file:\n",
    "    pickle.dump(kmeans_data3, file)\n",
    "    \n",
    "# Save the model to disk for data2\n",
    "filename_data4 = 'Kmeans_CL_5_Model_data4.sav'\n",
    "with open(filename_data4, 'wb') as file:\n",
    "    pickle.dump(kmeans_data4, file)\n",
    "    \n",
    "filename_data5 = 'Kmeans_CL_5_Model_data5.sav'\n",
    "with open(filename_data5, 'wb') as file:\n",
    "    pickle.dump(kmeans_data5, file)\n",
    "\n",
    "filename_data6 = 'Kmeans_CL_5_Model_data6.sav'\n",
    "with open(filename_data6, 'wb') as file:\n",
    "    pickle.dump(kmeans_data6, file)\n",
    "    \n",
    "filename_data7 = 'Kmeans_CL_5_Model_data7.sav'\n",
    "with open(filename_data7, 'wb') as file:\n",
    "    pickle.dump(kmeans_data7, file)\n",
    "    \n",
    "filename_data8 = 'Kmeans_CL_5_Model_data8.sav'\n",
    "with open(filename_data8, 'wb') as file:\n",
    "    pickle.dump(kmeans_data8, file)\n",
    "\n",
    "filename_data9 = 'Kmeans_CL_5_Model_data9.sav'\n",
    "with open(filename_data9, 'wb') as file:\n",
    "    pickle.dump(kmeans_data9, file)\n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db17c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of trained kmeans for data1:\n",
      "(array([1781, 2187, 2140, 1903, 1754, 2061, 2134, 2268, 1677, 1972, 2022,\n",
      "       1935,    0, 4231, 1989, 1880, 2344], dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data2:\n",
      "(array([2794, 2613, 2415, 2708, 2726, 3293, 2323, 2190, 1976, 1955, 2627,\n",
      "       2672,    0, 5753, 2127, 2535, 2940], dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data3:\n",
      "(array([ 8068,  6131,  8127,  7395,  7024,  6124,  6442,  6607,  6496,\n",
      "        6515,  7485,  8307,     0, 16384,  7797,  7716,  8312],\n",
      "      dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data4:\n",
      "(array([11260, 15750, 14562, 18295, 13449, 14323, 14893, 16691, 17148,\n",
      "       14759, 15273, 19201,     0, 32806, 15834, 14993, 11325],\n",
      "      dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data5:\n",
      "(array([ 8881,  8169,  7285,  6446,  8720,  7445,  6646,  7449, 10365,\n",
      "        7412,  6591,  8728,     0, 20735,  7701,  6896,  7212],\n",
      "      dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data6:\n",
      "(array([31956, 34894, 31141, 34838, 34802, 25348, 35733, 28252, 36500,\n",
      "       24877, 31301, 28659,     0, 57558, 25858, 35653, 39251],\n",
      "      dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data7:\n",
      "(array([ 8515, 10704, 13557, 10545, 12121, 10611, 11214, 12663, 10845,\n",
      "       10386, 11085, 11234,     0, 22255, 10121, 10584,  9949],\n",
      "      dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data8:\n",
      "(array([ 8710,  9201,  8375,  6736, 10049,  8778,  8568,  8883,  7781,\n",
      "        8937,  9053,  7601,     0, 16958,  6852,  7757,  7521],\n",
      "      dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n",
      "Histogram of trained kmeans for data9:\n",
      "(array([ 4654,  4769,  4261,  4911,  6476,  5003,  5583,  5060,  4146,\n",
      "        4200,  4388,  5503,     0, 10497,  3819,  4281,  3987],\n",
      "      dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 12, 14, 15, 16,\n",
      "       17])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data1 = np.histogram(kmeans_data1.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data1:')\n",
    "print(hist_data1, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data2 = np.histogram(kmeans_data2.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data2:')\n",
    "print(hist_data2, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data3 = np.histogram(kmeans_data3.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data3:')\n",
    "print(hist_data3, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data4 = np.histogram(kmeans_data4.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data4:')\n",
    "print(hist_data4, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data5 = np.histogram(kmeans_data5.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data5:')\n",
    "print(hist_data5, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data6 = np.histogram(kmeans_data6.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data6:')\n",
    "print(hist_data6, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data7 = np.histogram(kmeans_data7.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data7:')\n",
    "print(hist_data7, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data8 = np.histogram(kmeans_data8.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data8:')\n",
    "print(hist_data8, \"\\n\")\n",
    "\n",
    "# Compute histogram of trained Kmeans of data1\n",
    "hist_data9 = np.histogram(kmeans_data9.labels_, bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "print('Histogram of trained kmeans for data9:')\n",
    "print(hist_data9, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "000081e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "folder1=r\"D:/mine/train/Bull\"\n",
    "folder2=r\"D:/mine/train/Cattle\"\n",
    "folder3=r\"D:/mine/train/Elephant\"\n",
    "folder4=r\"D:/mine/train/Horse\"\n",
    "folder5=r\"D:/mine/train/Leopard\"\n",
    "folder6=r\"D:/mine/train/Monkey\"\n",
    "folder7=r\"D:/mine/train/Pig\"\n",
    "folder8=r\"D:/mine/train/Rabbit\"\n",
    "folder9=r\"D:/mine/train/Sheep\"\n",
    "\n",
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder1):\n",
    "    #path \n",
    "    path=os.path.join(folder1,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data1.predict(array_double)\n",
    "    \n",
    "    hist_data1=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data1[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output1 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output1[\"Class\"] = 1 \n",
    "csv_data=Output1.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset1.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aacca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder2):\n",
    "    #path \n",
    "    path=os.path.join(folder2,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data2.predict(array_double)\n",
    "    \n",
    "    hist_data2=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data2[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output2 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output2[\"Class\"] = 2\n",
    "csv_data=Output2.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset2.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46f92716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder3):\n",
    "    #path \n",
    "    path=os.path.join(folder3,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data3.predict(array_double)\n",
    "    \n",
    "    hist_data3=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data3[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output3 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output3[\"Class\"] = 3\n",
    "csv_data=Output3.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset3.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6832dd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder4):\n",
    "    #path \n",
    "    path=os.path.join(folder4,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data4.predict(array_double)\n",
    "    \n",
    "    hist_data4=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data4[0])\n",
    "    #k=k+1\n",
    "\n",
    "Output4 = pd.DataFrame(data)\n",
    "Output4[\"Class\"] = 4\n",
    "csv_data=Output4.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset4.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413de3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder5):\n",
    "    #path \n",
    "    path=os.path.join(folder5,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data5.predict(array_double)\n",
    "    \n",
    "    hist_data5=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data5[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output5 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output5[\"Class\"] = 5\n",
    "csv_data=Output5.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset5.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3bf792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder6):\n",
    "    #path \n",
    "    path=os.path.join(folder6,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data6.predict(array_double)\n",
    "    \n",
    "    hist_data6=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data6[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output6 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output6[\"Class\"] = 6\n",
    "csv_data=Output6.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset6.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed11ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder7):\n",
    "    #path \n",
    "    path=os.path.join(folder7,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data7.predict(array_double)\n",
    "    \n",
    "    hist_data7=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data7[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output7 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output7[\"Class\"] = 7\n",
    "csv_data=Output7.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset7.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fd6b4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder8):\n",
    "    #path \n",
    "    path=os.path.join(folder8,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data8.predict(array_double)\n",
    "    \n",
    "    hist_data8=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data8[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output8 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output8[\"Class\"] = 8\n",
    "csv_data=Output8.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset8.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbe5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#performing kmeans prediction of the entire bottle dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "#k=0\n",
    "\n",
    "for filename in os.listdir(folder9):\n",
    "    #path \n",
    "    path=os.path.join(folder9,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(280,430)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans_data9.predict(array_double)\n",
    "    \n",
    "    hist_data9=np.histogram(a,bins=[0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,12,14,15,16,17])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist_data9[0])\n",
    "    #k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output9 = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output9[\"Class\"] = 9\n",
    "csv_data=Output1.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Dataset9.csv', mode='a',header=False,index=False)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2a38f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bull\n",
      "     0    1    2    3    4    5    6    7    8    9   10   11  12   13   14  \\\n",
      "0   15    5   36   16   20    9   22   13   16   19   21    7   0   28   21   \n",
      "1   53   60   55   60   22   28   48   58   30   23   41   31   0  121   19   \n",
      "2   37   39   22   41   48   29   54   44   39   76   38   78   0   99   63   \n",
      "3   37   34   64   83   45   29   51   53   47   42   60   47   0  150   31   \n",
      "4   31   46   30   35   31   55   47   34   26   50   54   75   0   91   58   \n",
      "5   44   41   34   12   28   22   33   77   47   17   35   50   0   75   21   \n",
      "6   35   37   54   43   30   61   57   85   34   32   40   32   0  100   69   \n",
      "7   49   38   63   45   42   45   60   28   41   40   49   36   0   87   57   \n",
      "8   39   40   46   64   25   17   28   42   28   40   18   20   0   90   20   \n",
      "9   35  160   34   11   60   72   55   92   35   76   51   64   0   83   52   \n",
      "10   8   11    3    0    4   38   18    7    4    7   11    5   0   13   25   \n",
      "11   9    6    8    0    8   33    7   23    6   19    7    4   0   11   38   \n",
      "12  33   38   28   23   20   69   39   13   17   44   32   28   0   56   56   \n",
      "13  40   33   66  104   48   34   58   41   40   26   47   36   0  119   53   \n",
      "14  45   38   54   57   40  111   57   44   50   44   57   44   0  119   83   \n",
      "15  23   36   17   29   16   69   39   16    7   51   39   34   0   61   63   \n",
      "16  59   70   71   82   57   32   52   53   47   62   56   68   0  143   44   \n",
      "17   9    6    1    0    1   10    4    6    0    9    8   11   0   10    3   \n",
      "18  49   34   44   44   23   23   31   46   53   19   26   46   0  108   30   \n",
      "19  12    8    3    8    3   29   14    9    0   29   20   22   0   13   24   \n",
      "20  70  192   96  110  105   31   76  193  107   79   75   74   0  213   30   \n",
      "21  82   92  116   70  123   46  138   58  117  120  119  103   0  214   32   \n",
      "22  36   88   16   25   15   11   26  165   14   29   20   27   0  102   10   \n",
      "23  48   76   45   11   60   15   58  150   35   45   49   53   0   73    5   \n",
      "24  21   23   25   31   14   46   34   32   14   22   28   21   0   74   41   \n",
      "25  15   15   19   64   58   31   27    8   62   22   30   73   0  112   27   \n",
      "26   7    8   13    5    1    9   14    0    2    2   15    2   0   25   14   \n",
      "27  63   93   71   94   88   42   68   45   68   67   83   70   0  161   67   \n",
      "28  19   13   34    6   13   93   20   35   22   22   15   11   0   26  106   \n",
      "29  45   50   58   42   18   27   59   66   42   26   50   36   0  156   38   \n",
      "30  23   31   39   30   31   29   27   30   20   59   39   26   0   52   34   \n",
      "31  67  100   72   59   64   57   71   30   61   94   82   73   0  140   48   \n",
      "32  43   41   24   46   30   65   62   24   25   70   50   43   0   70   67   \n",
      "33  29   13   20   11   19   64   32   12   13   19   33   13   0   60   73   \n",
      "34  20   20   17   26   24   39   21   11   23   28   17   26   0   48   50   \n",
      "35  25   27    8   24   18   44   19   17    5   27   30   37   0   52   49   \n",
      "36  40  110   46   14   38  113   46   95   29   74   62   49   0   77   71   \n",
      "37  42   41   71   49   42   88   58   47   40   44   65   40   0  107   32   \n",
      "38  68   49   76   44   44   46   77   38   38   70   61   48   0  145   38   \n",
      "39  58   58   76   64   69   52   78   56   68   54   70   57   0  120   40   \n",
      "40  20   28   52   36   21   77   30   22   21   45   37   29   0   71   56   \n",
      "41  45   34   22   23   28   36   35   54   15   29   37   29   0   54   48   \n",
      "42  55   59  138   78  130   24   96  111  115   76   90  107   0  143   20   \n",
      "43  41   46   45   43   42   55   47   24   50   51   40   45   0  113   38   \n",
      "44  63   37  122   48   35   22   48  120   58   18   46   51   0  106   47   \n",
      "45  30   16   26   17   16   46   32   16   10   18   19   16   0   48   35   \n",
      "46  44   47   60   76   37   38   61   25   36   37   50   38   0   92   43   \n",
      "\n",
      "     15   16  Class  \n",
      "0    10   28      1  \n",
      "1    32   36      1  \n",
      "2    45   34      1  \n",
      "3    53   86      1  \n",
      "4    38   25      1  \n",
      "5    53   43      1  \n",
      "6    51   68      1  \n",
      "7    48   34      1  \n",
      "8    29   23      1  \n",
      "9    60   60      1  \n",
      "10    5    5      1  \n",
      "11   10    4      1  \n",
      "12   21   19      1  \n",
      "13   33   60      1  \n",
      "14   49   30      1  \n",
      "15   29    9      1  \n",
      "16   44   59      1  \n",
      "17    7    0      1  \n",
      "18   57   50      1  \n",
      "19    7    8      1  \n",
      "20   93  236      1  \n",
      "21  100  120      1  \n",
      "22   48   28      1  \n",
      "23   83  159      1  \n",
      "24   27   15      1  \n",
      "25   24   12      1  \n",
      "26    5    2      1  \n",
      "27   57   75      1  \n",
      "28   26   28      1  \n",
      "29   33   95      1  \n",
      "30   33   17      1  \n",
      "31   48   66      1  \n",
      "32   31   12      1  \n",
      "33   18   12      1  \n",
      "34    7   11      1  \n",
      "35   24   11      1  \n",
      "36   44   87      1  \n",
      "37   51   64      1  \n",
      "38   40   63      1  \n",
      "39   83   81      1  \n",
      "40   27   31      1  \n",
      "41   27   34      1  \n",
      "42  120  185      1  \n",
      "43   34   42      1  \n",
      "44   63  102      1  \n",
      "45   13   32      1  \n",
      "46   40   42      1  \n"
     ]
    }
   ],
   "source": [
    "print(\"Bull\")\n",
    "print(Output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8a40357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>76</td>\n",
       "      <td>38</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>63</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>58</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>94</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>106</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>71</td>\n",
       "      <td>103</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>181</td>\n",
       "      <td>87</td>\n",
       "      <td>112</td>\n",
       "      <td>104</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>49</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>56</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2069 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1   2   3    4   5    6    7   8   9  10  11  12   13  14  15  16  \\\n",
       "0     15    5  36  16   20   9   22   13  16  19  21   7   0   28  21  10  28   \n",
       "1     53   60  55  60   22  28   48   58  30  23  41  31   0  121  19  32  36   \n",
       "2     37   39  22  41   48  29   54   44  39  76  38  78   0   99  63  45  34   \n",
       "3     37   34  64  83   45  29   51   53  47  42  60  47   0  150  31  53  86   \n",
       "4     31   46  30  35   31  55   47   34  26  50  54  75   0   91  58  38  25   \n",
       "...   ..  ...  ..  ..  ...  ..  ...  ...  ..  ..  ..  ..  ..  ...  ..  ..  ..   \n",
       "2064  43   25  71  92   29  27   27   18  94  71  74  79   0  125  29  24  77   \n",
       "2065  35   33  20  53  106  42   52   41  57  22  29  44   0   85  16  33  43   \n",
       "2066  30   43  13  57   42  46   34   39  61  36   6  51   0   55  39  40  43   \n",
       "2067  71  103  19  46  181  87  112  104  37  30  28  68   0  181  55  48  68   \n",
       "2068  49   68  80  70   28  72   39   51  86  85  57  81   0   82  33  56  75   \n",
       "\n",
       "      Class  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "2064      9  \n",
       "2065      9  \n",
       "2066      9  \n",
       "2067      9  \n",
       "2068      9  \n",
       "\n",
       "[2069 rows x 18 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = pd.concat([Output1, Output2, Output3,Output4,Output5,Output6,Output7,Output8,Output9], ignore_index=True)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b8a1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data=A.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Final_SIFT\\FinalSIFT.csv', mode='a',header=False,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26b2fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e8e814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "Data_SIFT=A\n",
    "Data_SIFT\n",
    "df = pd.DataFrame(Data_SIFT)\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7e30207",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data=df.to_csv(r'D:/cv_final_project\\z\\17kmeans\\Final_SIFT\\FinalFusedSIFT.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e14cb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>76</td>\n",
       "      <td>38</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>63</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>58</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>94</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>106</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>71</td>\n",
       "      <td>103</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>181</td>\n",
       "      <td>87</td>\n",
       "      <td>112</td>\n",
       "      <td>104</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>49</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>56</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2069 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4   5    6    7   8   9   10  11  12   13  14  15  16  \\\n",
       "0     15    5  36  16   20   9   22   13  16  19  21   7   0   28  21  10  28   \n",
       "1     53   60  55  60   22  28   48   58  30  23  41  31   0  121  19  32  36   \n",
       "2     37   39  22  41   48  29   54   44  39  76  38  78   0   99  63  45  34   \n",
       "3     37   34  64  83   45  29   51   53  47  42  60  47   0  150  31  53  86   \n",
       "4     31   46  30  35   31  55   47   34  26  50  54  75   0   91  58  38  25   \n",
       "...   ..  ...  ..  ..  ...  ..  ...  ...  ..  ..  ..  ..  ..  ...  ..  ..  ..   \n",
       "2064  43   25  71  92   29  27   27   18  94  71  74  79   0  125  29  24  77   \n",
       "2065  35   33  20  53  106  42   52   41  57  22  29  44   0   85  16  33  43   \n",
       "2066  30   43  13  57   42  46   34   39  61  36   6  51   0   55  39  40  43   \n",
       "2067  71  103  19  46  181  87  112  104  37  30  28  68   0  181  55  48  68   \n",
       "2068  49   68  80  70   28  72   39   51  86  85  57  81   0   82  33  56  75   \n",
       "\n",
       "      17  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "...   ..  \n",
       "2064   9  \n",
       "2065   9  \n",
       "2066   9  \n",
       "2067   9  \n",
       "2068   9  \n",
       "\n",
       "[2069 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_features = pd.read_csv(r'D:/cv_final_project\\z\\17kmeans\\Final_SIFT\\FinalFusedSIFT.csv',header=None)\n",
    "reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1114f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_features.isnull().values.any()\n",
    "X = reduced_features.drop(columns= 17, axis=1)\n",
    "Y = reduced_features[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ca3046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (1655, 17)\n",
      "Number transactions y_train dataset:  (1655,)\n",
      "Number transactions X_test dataset:  (414, 17)\n",
      "Number transactions y_test dataset:  (414,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,\n",
    "                                                 test_size=0.2, random_state = 0)\n",
    "# describes info about train and test set\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", Y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee2d817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train data:  0.5709969788519638\n",
      "Precision: 0.7162623152732953\n",
      "Recall: 0.5709969788519638\n",
      "F1 score: 0.6219015636835777\n",
      "Confusion Matrix for Training Data:\n",
      "[[  0   0   0   0   0   0   2   0   0]\n",
      " [  0   5   2   1   1   1   3   2   0]\n",
      " [  2   1  32  11   4   7   1   2  12]\n",
      " [ 17   2  21 225  14  28  40  27  21]\n",
      " [  1   1  11   5  47   6   6   2   2]\n",
      " [ 13  40  43  65  22 555  45  86  28]\n",
      " [  0   2   4   9   4  16  43  11   8]\n",
      " [  1   4   8   5   9   3   9  30   8]\n",
      " [  0   3   1   1   0   0   3   3   8]]\n",
      "\n",
      "Accuracy on Test data:  0.5507246376811594\n",
      "Precision: 0.695181375959408\n",
      "Recall: 0.5507246376811594\n",
      "F1 score: 0.6026263750144251\n",
      "\n",
      "Confusion Matrix for Testing Data:\n",
      "[[  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   1   0   0]\n",
      " [  1   1  12   6   2   2   2   2   0]\n",
      " [  5   3   4  48   4   7   9  11   2]\n",
      " [  1   0   1   1  10   4   0   0   0]\n",
      " [  4   6  11  17   4 138   8  34   4]\n",
      " [  1   0   0   1   1   3  13   0   2]\n",
      " [  1   0   2   5   1   0   5   4   1]\n",
      " [  0   2   0   0   0   0   0   1   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "modelLR = LogisticRegression(max_iter=1000, random_state=42)\n",
    "modelLR.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Accuracy on training data\n",
    "X_train_prediction = modelLR.predict(X_train)\n",
    "train_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "print('Accuracy on Train data: ', train_data_accuracy)\n",
    "print('Precision:', precision_score(X_train_prediction, Y_train, average='weighted'))\n",
    "print('Recall:', recall_score(X_train_prediction, Y_train, average='weighted'))\n",
    "print('F1 score:', f1_score(X_train_prediction, Y_train, average='weighted'))\n",
    "train_confusion_matrix = confusion_matrix(X_train_prediction, Y_train)\n",
    "print(\"Confusion Matrix for Training Data:\")\n",
    "print(train_confusion_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy on test data\n",
    "X_test_prediction = modelLR.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "print('\\nAccuracy on Test data: ', test_data_accuracy)\n",
    "print('Precision:', precision_score(X_test_prediction, Y_test, average='weighted'))\n",
    "print('Recall:', recall_score(X_test_prediction, Y_test, average='weighted'))\n",
    "print('F1 score:', f1_score(X_test_prediction, Y_test, average='weighted'))\n",
    "test_confusion_matrix = confusion_matrix(X_test_prediction, Y_test)\n",
    "print(\"\\nConfusion Matrix for Testing Data:\")\n",
    "print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130e28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Data:  0.8459214501510574\n",
      "Precision on Training Data:  0.8572258250771057\n",
      "Recall on Training Data:  0.8459214501510574\n",
      "F1 Score on Training Data:  0.8489906915108125\n",
      "Confusion Matrix (Training Data):\n",
      " [[ 23   0   1   7   0   1   0   1   1]\n",
      " [  0  37   1   2   2  13   2   0   1]\n",
      " [  2   0  91   4   4  13   4   0   4]\n",
      " [  0   2   5 289   4  12   7   0   3]\n",
      " [  2   2   2   3  77   9   6   0   0]\n",
      " [  2   2   4   8   1 584  11   2   2]\n",
      " [  1   1   1  14   2   9 121   1   2]\n",
      " [  0   1   4   5   3  10   8 131   1]\n",
      " [  0   2   4   5   3  17   8   1  47]]\n",
      "\n",
      "Accuracy on Test Data:  0.6014492753623188\n",
      "Precision on Test Data:  0.6224193215039897\n",
      "Recall on Test Data:  0.6014492753623188\n",
      "F1 Score on Test Data:  0.6084417006875994\n",
      "Confusion Matrix (Test Data):\n",
      " [[  1   0   2   3   1   5   0   1   0]\n",
      " [  1   4   0   4   0   2   0   1   0]\n",
      " [  5   0  16   1   2   6   2   0   1]\n",
      " [  2   0   2  55   5   6   3   2   3]\n",
      " [  0   0   2   2  11   4   1   0   2]\n",
      " [  0   3   6   9   2 122   5   6   1]\n",
      " [  1   0   3   6   5   9  12   2   0]\n",
      " [  0   2   0   5   2  11   3  26   3]\n",
      " [  1   1   1   2   1   2   2   0   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "modelDT = DecisionTreeClassifier(max_depth=9)\n",
    "\n",
    "# Train the model on the training data\n",
    "modelDT.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the training data\n",
    "X_train_prediction = modelDT.predict(X_train)\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "print('Accuracy on Training Data: ', train_data_accuracy)\n",
    "\n",
    "# Calculate precision on training data\n",
    "train_data_precision = precision_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('Precision on Training Data: ', train_data_precision)\n",
    "\n",
    "# Calculate recall on training data\n",
    "train_data_recall = recall_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('Recall on Training Data: ', train_data_recall)\n",
    "\n",
    "# Calculate F1 score on training data\n",
    "train_data_f1_score = f1_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('F1 Score on Training Data: ', train_data_f1_score)\n",
    "\n",
    "# Generate a confusion matrix for training data\n",
    "confusion_matrix_train = confusion_matrix(Y_train, X_train_prediction)\n",
    "print('Confusion Matrix (Training Data):\\n', confusion_matrix_train)\n",
    "\n",
    "# Predict on the test data\n",
    "X_test_prediction = modelDT.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "print('\\nAccuracy on Test Data: ', test_data_accuracy)\n",
    "\n",
    "# Calculate precision on test data\n",
    "test_data_precision = precision_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('Precision on Test Data: ', test_data_precision)\n",
    "\n",
    "# Calculate recall on test data\n",
    "test_data_recall = recall_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('Recall on Test Data: ', test_data_recall)\n",
    "\n",
    "# Calculate F1 score on test data\n",
    "test_data_f1_score = f1_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('F1 Score on Test Data: ', test_data_f1_score)\n",
    "\n",
    "# Generate a confusion matrix for test data\n",
    "confusion_matrix_test = confusion_matrix(Y_test, X_test_prediction)\n",
    "print('Confusion Matrix (Test Data):\\n', confusion_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed6d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Data:  1.0\n",
      "Precision on Training Data:  1.0\n",
      "Recall on Training Data:  1.0\n",
      "F1 Score on Training Data:  1.0\n",
      "Confusion Matrix (Training Data):\n",
      " [[ 34   0   0   0   0   0   0   0   0]\n",
      " [  0  58   0   0   0   0   0   0   0]\n",
      " [  0   0 122   0   0   0   0   0   0]\n",
      " [  0   0   0 322   0   0   0   0   0]\n",
      " [  0   0   0   0 101   0   0   0   0]\n",
      " [  0   0   0   0   0 616   0   0   0]\n",
      " [  0   0   0   0   0   0 152   0   0]\n",
      " [  0   0   0   0   0   0   0 163   0]\n",
      " [  0   0   0   0   0   0   0   0  87]]\n",
      "\n",
      "Accuracy on Test Data:  0.7946859903381642\n",
      "Precision on Test Data:  0.8658221069548301\n",
      "Recall on Test Data:  0.7946859903381642\n",
      "F1 Score on Test Data:  0.8160479717565562\n",
      "Confusion Matrix (Test Data):\n",
      " [[  1   0   0   4   0   8   0   0   0]\n",
      " [  0   2   1   2   0   6   0   0   1]\n",
      " [  0   0  26   2   0   5   0   0   0]\n",
      " [  1   0   2  67   2   6   0   0   0]\n",
      " [  0   0   0   2  16   4   0   0   0]\n",
      " [  0   0   0   1   0 152   1   0   0]\n",
      " [  0   0   1   3   3   5  26   0   0]\n",
      " [  0   0   0   5   0  10   1  35   1]\n",
      " [  0   0   0   2   0   4   0   2   4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "modelRF = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "modelRF.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the training data\n",
    "X_train_prediction = modelRF.predict(X_train)\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "print('Accuracy on Training Data: ', train_data_accuracy)\n",
    "\n",
    "# Calculate precision on training data\n",
    "train_data_precision = precision_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('Precision on Training Data: ', train_data_precision)\n",
    "\n",
    "# Calculate recall on training data\n",
    "train_data_recall = recall_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('Recall on Training Data: ', train_data_recall)\n",
    "\n",
    "# Calculate F1 score on training data\n",
    "train_data_f1_score = f1_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('F1 Score on Training Data: ', train_data_f1_score)\n",
    "\n",
    "# Generate a confusion matrix for training data\n",
    "confusion_matrix_train = confusion_matrix(Y_train, X_train_prediction)\n",
    "print('Confusion Matrix (Training Data):\\n', confusion_matrix_train)\n",
    "\n",
    "# Predict on the test data\n",
    "X_test_prediction = modelRF.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "print('\\nAccuracy on Test Data: ', test_data_accuracy)\n",
    "\n",
    "# Calculate precision on test data\n",
    "test_data_precision = precision_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('Precision on Test Data: ', test_data_precision)\n",
    "\n",
    "# Calculate recall on test data\n",
    "test_data_recall = recall_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('Recall on Test Data: ', test_data_recall)\n",
    "\n",
    "# Calculate F1 score on test data\n",
    "test_data_f1_score = f1_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('F1 Score on Test Data: ', test_data_f1_score)\n",
    "\n",
    "# Generate a confusion matrix for test data\n",
    "confusion_matrix_test = confusion_matrix(Y_test, X_test_prediction)\n",
    "print('Confusion Matrix (Test Data):\\n', confusion_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbab5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Data:  0.6996978851963747\n",
      "Precision on Training Data:  0.7648740272638946\n",
      "Recall on Training Data:  0.6996978851963747\n",
      "F1 Score on Training Data:  0.7205657946973462\n",
      "Confusion Matrix (Training Data):\n",
      " [[  5   0   5  13   0   6   0   5   0]\n",
      " [  0  19   0   0   1  32   4   0   2]\n",
      " [  1   2  70  10  13  20   2   3   1]\n",
      " [  0   2   8 263   3  32   7   4   3]\n",
      " [  2   0   6  10  69   9   1   3   1]\n",
      " [  2   2   7  18   9 563  14   1   0]\n",
      " [  2   1   2  33   4  26  75   8   1]\n",
      " [  1   4   3  26   0  55   4  69   1]\n",
      " [  0   2  14  21   3  11   4   7  25]]\n",
      "\n",
      "Accuracy on Test Data:  0.6908212560386473\n",
      "Precision on Test Data:  0.7530605147882037\n",
      "Recall on Test Data:  0.6908212560386473\n",
      "F1 Score on Test Data:  0.7110137477080251\n",
      "Confusion Matrix (Test Data):\n",
      " [[  1   1   0   7   0   3   0   1   0]\n",
      " [  0   3   2   2   0   3   1   0   1]\n",
      " [  0   1  22   1   3   4   0   2   0]\n",
      " [  2   0   6  63   1   3   1   2   0]\n",
      " [  0   1   1   4  14   1   1   0   0]\n",
      " [  0   0   4   2   3 140   3   2   0]\n",
      " [  0   1   1   7   3   4  20   2   0]\n",
      " [  0   1   2  12   1  17   0  19   0]\n",
      " [  0   3   1   2   0   1   1   0   4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Create an SVM classifier with a linear kernel\n",
    "modelSVM = SVC(kernel='linear')\n",
    "\n",
    "# Train the model on the training data\n",
    "modelSVM.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the training data\n",
    "X_train_prediction = modelSVM.predict(X_train)\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "print('Accuracy on Training Data: ', train_data_accuracy)\n",
    "\n",
    "# Calculate precision on training data\n",
    "train_data_precision = precision_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('Precision on Training Data: ', train_data_precision)\n",
    "\n",
    "# Calculate recall on training data\n",
    "train_data_recall = recall_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('Recall on Training Data: ', train_data_recall)\n",
    "\n",
    "# Calculate F1 score on training data\n",
    "train_data_f1_score = f1_score(X_train_prediction, Y_train, average='weighted')\n",
    "print('F1 Score on Training Data: ', train_data_f1_score)\n",
    "\n",
    "# Generate a confusion matrix for training data\n",
    "confusion_matrix_train = confusion_matrix(Y_train, X_train_prediction)\n",
    "print('Confusion Matrix (Training Data):\\n', confusion_matrix_train)\n",
    "\n",
    "# Predict on the test data\n",
    "X_test_prediction = modelSVM.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "print('\\nAccuracy on Test Data: ', test_data_accuracy)\n",
    "\n",
    "# Calculate precision on test data\n",
    "test_data_precision = precision_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('Precision on Test Data: ', test_data_precision)\n",
    "\n",
    "# Calculate recall on test data\n",
    "test_data_recall = recall_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('Recall on Test Data: ', test_data_recall)\n",
    "\n",
    "# Calculate F1 score on test data\n",
    "test_data_f1_score = f1_score(X_test_prediction, Y_test, average='weighted')\n",
    "print('F1 Score on Test Data: ', test_data_f1_score)\n",
    "\n",
    "# Generate a confusion matrix for test data\n",
    "confusion_matrix_test = confusion_matrix(Y_test, X_test_prediction)\n",
    "print('Confusion Matrix (Test Data):\\n', confusion_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978301fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
